{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "\n",
    "# Load CSV files from the Kaggle input directory\n",
    "account_booking = pd.read_csv('data/account_booking_test.csv')\n",
    "external_parties = pd.read_csv('data/external_parties_test.csv')\n",
    "\n",
    "\n",
    "class LSHEntityResolution:\n",
    "    def __init__(self, dataframe):\n",
    "        \"\"\"\n",
    "        Initialize with the DataFrame.\n",
    "        :param dataframe: Pandas DataFrame containing entity data.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    # Generate MinHash for a given text\n",
    "    def generate_minhash(self, text, num_perm=128):\n",
    "        \"\"\"\n",
    "        Create MinHash for a given text.\n",
    "        :param text: Input string.\n",
    "        :param num_perm: Number of permutations for MinHash.\n",
    "        :return: MinHash object.\n",
    "        \"\"\"\n",
    "        if not text or pd.isna(text):\n",
    "            return None\n",
    "        mh = MinHash(num_perm=num_perm)\n",
    "        for token in text.split():\n",
    "            mh.update(token.encode(\"utf8\"))\n",
    "        return mh\n",
    "\n",
    "    # Perform LSH on nodes\n",
    "    def perform_lsh(self, threshold=0.8, num_perm=128):\n",
    "        \"\"\"\n",
    "        Perform LSH to find similar entities.\n",
    "        :param threshold: Similarity threshold for LSH.\n",
    "        :param num_perm: Number of permutations for MinHash.\n",
    "        :return: List of matched entity pairs.\n",
    "        \"\"\"\n",
    "        lsh = MinHashLSH(threshold=threshold, num_perm=num_perm)\n",
    "        node_hashes = {}\n",
    "\n",
    "        # Insert nodes into LSH\n",
    "        for index, row in self.dataframe.iterrows():\n",
    "            combined_text = \" \".join(\n",
    "                filter(None, [\n",
    "                    str(row['parsed_name']), \n",
    "                    str(row['parsed_address_street_name']), \n",
    "                    str(row['parsed_address_city'])                    \n",
    "                ])\n",
    "            )\n",
    "            mh = self.generate_minhash(combined_text, num_perm)\n",
    "            if mh:\n",
    "                lsh.insert(str(index), mh)\n",
    "                node_hashes[str(index)] = mh\n",
    "\n",
    "        # Find similar pairs\n",
    "        matches = []\n",
    "        for node_id, mh in node_hashes.items():\n",
    "            similar = lsh.query(mh)\n",
    "            for sim in similar:\n",
    "                if int(node_id) < int(sim):  # Avoid duplicate matches (e.g., (A, B) and (B, A))\n",
    "                    matches.append((int(node_id), int(sim)))\n",
    "\n",
    "        return matches\n",
    "\n",
    "\n",
    "# Instantiate the LSHEntityResolution class\n",
    "lsh_er = LSHEntityResolution(external_parties)\n",
    "\n",
    "# Perform LSH to find matches\n",
    "matches = lsh_er.perform_lsh(threshold=0.6, num_perm=264)\n",
    "\n",
    "\n",
    "# Function to create submission file\n",
    "def create_submission(dataframe, matches, remove_singletons=True):\n",
    "    \"\"\"\n",
    "    Create a Kaggle submission file for entity resolution.\n",
    "    :param dataframe: DataFrame containing the test data.\n",
    "    :param matches: List of matched entity pairs.\n",
    "    :param remove_singletons: If True, remove singletons from the submission.\n",
    "    :return: DataFrame ready for submission.\n",
    "    \"\"\"\n",
    "    # Initialize clusters\n",
    "    cluster_map = {}\n",
    "    cluster_id = 1\n",
    "\n",
    "    # Group matches into clusters\n",
    "    for match in matches:\n",
    "        id1, id2 = match\n",
    "        if id1 in cluster_map and id2 in cluster_map:\n",
    "            # Merge clusters if both are already in clusters\n",
    "            old_cluster = cluster_map[id2]\n",
    "            for key, value in cluster_map.items():\n",
    "                if value == old_cluster:\n",
    "                    cluster_map[key] = cluster_map[id1]\n",
    "        elif id1 in cluster_map:\n",
    "            cluster_map[id2] = cluster_map[id1]\n",
    "        elif id2 in cluster_map:\n",
    "            cluster_map[id1] = cluster_map[id2]\n",
    "        else:\n",
    "            # Assign new cluster ID if neither is in a cluster\n",
    "            cluster_map[id1] = cluster_id\n",
    "            cluster_map[id2] = cluster_id\n",
    "            cluster_id += 1\n",
    "\n",
    "    # Assign unique clusters to singletons\n",
    "    for index in dataframe.index:\n",
    "        if index not in cluster_map:\n",
    "            if remove_singletons:\n",
    "                cluster_map[index] = None  # Mark singleton for removal\n",
    "            else:\n",
    "                cluster_map[index] = cluster_id  # Assign unique ID\n",
    "                cluster_id += 1\n",
    "\n",
    "    # Create the submission DataFrame\n",
    "    submission = dataframe[['transaction_reference_id']].copy()\n",
    "    submission['external_id'] = dataframe.index.map(cluster_map)\n",
    "\n",
    "    # Remove singletons if required\n",
    "    if remove_singletons:\n",
    "        submission = submission.dropna(subset=['external_id'])\n",
    "\n",
    "    # Convert external_id to integer\n",
    "    submission['external_id'] = submission['external_id'].astype(int)\n",
    "\n",
    "    return submission\n",
    "\n",
    "\n",
    "# Prepare the submission DataFrame\n",
    "submission_df = create_submission(account_booking, matches, remove_singletons=True)\n",
    "\n",
    "# Save to CSV for Kaggle submission\n",
    "submission_df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
