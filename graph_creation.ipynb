{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import uuid  # For generating unique IDs\n",
    "import math\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "\n",
    "\n",
    "# Load CSV files\n",
    "account_booking_train = pd.read_csv('data/account_booking_train.csv')\n",
    "external_parties_train = pd.read_csv('data/external_parties_train.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the Data\n",
    "# Clean the Data\n",
    "# Step 1: Identify transaction counts by `transaction_reference_id`\n",
    "transaction_counts = account_booking_train['transaction_reference_id'].value_counts()\n",
    "\n",
    "# Step 2: Filter transactions with only one leg\n",
    "single_leg_transactions = transaction_counts[transaction_counts == 1].index\n",
    "\n",
    "# Step 3: Filter the dataset for these transactions\n",
    "account_booking_train = account_booking_train[\n",
    "    account_booking_train['transaction_reference_id'].isin(single_leg_transactions)\n",
    "]\n",
    "\n",
    "\n",
    "def sanitize_value(value):\n",
    "    \"\"\"Replace NaN with None to avoid Neo4j errors.\"\"\"\n",
    "    if value is None or (isinstance(value, float) and math.isnan(value)):\n",
    "        return None\n",
    "    return value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4j connection details\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"password123\"\n",
    "\n",
    "class Neo4jLoader:\n",
    "    def __init__(self, uri, username, password):\n",
    "        \"\"\"Initialize the Neo4j driver.\"\"\"\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the Neo4j driver connection.\"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.close()\n",
    "\n",
    "    def create_constraints(self):\n",
    "        \"\"\"Create unique constraints for External_Party nodes.\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            try:\n",
    "                session.run(\"\"\"\n",
    "                CREATE CONSTRAINT unique_party_id IF NOT EXISTS\n",
    "                FOR (p:External_Party) REQUIRE p.id IS UNIQUE\n",
    "                \"\"\")\n",
    "                print(\"Constraint 'unique_party_id' created successfully.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating 'unique_party_id' constraint: {e}\")\n",
    "\n",
    "    def load_external_parties(self, session, external_parties_train):\n",
    "        \"\"\"Load external parties as nodes.\"\"\"\n",
    "        for _, row in external_parties_train.iterrows():\n",
    "            unique_party_id = str(uuid.uuid4())\n",
    "            try:\n",
    "                # Prepare non-null properties\n",
    "\n",
    "\n",
    "                properties = {\n",
    "                    \"id\": unique_party_id,\n",
    "                    \"transaction_reference_id\": sanitize_value(row.get('transaction_reference_id')),\n",
    "                    \"party_role\": sanitize_value(row.get('party_role')),\n",
    "                    \"party_info_unstructured\": sanitize_value(row.get('party_info_unstructured')),\n",
    "                    \"parsed_name\": sanitize_value(row.get('parsed_name')),\n",
    "                    \"parsed_address_street_name\": sanitize_value(row.get('parsed_address_street_name')),\n",
    "                    \"parsed_address_street_number\": sanitize_value(row.get('parsed_address_street_number')),\n",
    "                    \"parsed_address_unit\": sanitize_value(row.get('parsed_address_unit')),\n",
    "                    \"parsed_address_postal_code\": sanitize_value(row.get('parsed_address_postal_code')),\n",
    "                    \"parsed_address_city\": sanitize_value(row.get('parsed_address_city')),\n",
    "                    \"parsed_address_state\": sanitize_value(row.get('parsed_address_state')),\n",
    "                    \"parsed_address_country\": sanitize_value(row.get('parsed_address_country')),\n",
    "                    \"party_iban\": sanitize_value(row.get('party_iban')),\n",
    "                    \"party_phone\": sanitize_value(row.get('party_phone')),\n",
    "                    \"external_id\": sanitize_value(row.get('external_id'))\n",
    "                }\n",
    "                # Remove None values from properties\n",
    "                non_null_properties = {k: v for k, v in properties.items() if v is not None}\n",
    "\n",
    "                # Dynamically construct Cypher query\n",
    "                query = f\"MERGE (p:External_Party {{{', '.join([f'{k}: ${k}' for k in non_null_properties.keys()])}}})\"\n",
    "                session.run(query, non_null_properties)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading External_Party node: {e}\")\n",
    "\n",
    "    def load_transactions_as_relationships(self, session, account_booking_train):\n",
    "        \"\"\"Load transactions as relationships between UBS_Client and External_Party nodes.\"\"\"\n",
    "        for _, row in account_booking_train.iterrows():\n",
    "            try:\n",
    "                # Prepare transaction properties\n",
    "                properties = {\n",
    "                    \"transaction_reference_id\": sanitize_value(row.get('transaction_reference_id')),\n",
    "                    \"debit_credit_indicator\": sanitize_value(row.get('debit_credit_indicator')),\n",
    "                    \"account_id\": sanitize_value(row.get('account_id')),\n",
    "                    \"transaction_amount\": sanitize_value(row.get('transaction_amount')),\n",
    "                    \"transaction_currency\": sanitize_value(row.get('transaction_currency')),\n",
    "                    \"transaction_date\": sanitize_value(row.get('transaction_date'))\n",
    "                }\n",
    "                # Remove None values from properties\n",
    "                non_null_properties = {k: v for k, v in properties.items() if v is not None}\n",
    "\n",
    "                # Ensure account_id is present\n",
    "                if \"account_id\" not in non_null_properties or \"transaction_reference_id\" not in non_null_properties:\n",
    "                    print(f\"Skipping row due to missing required fields: {row}\")\n",
    "                    continue\n",
    "\n",
    "                # Dynamically construct Cypher queries\n",
    "                create_ubs_client_query = \"\"\"\n",
    "                MERGE (c:UBS_Client {account_id: $account_id})\n",
    "                \"\"\"\n",
    "                create_transaction_relationship_query = \"\"\"\n",
    "                MATCH (c:UBS_Client {account_id: $account_id}),\n",
    "                    (p:External_Party {transaction_reference_id: $transaction_reference_id})\n",
    "                MERGE (c)-[:TRANSACTION {\n",
    "                    debit_credit_indicator: $debit_credit_indicator,\n",
    "                    transaction_amount: $transaction_amount,\n",
    "                    transaction_currency: $transaction_currency,\n",
    "                    transaction_date: $transaction_date\n",
    "                }]->(p)\n",
    "                \"\"\"\n",
    "\n",
    "                # Execute queries\n",
    "                session.run(create_ubs_client_query, {\"account_id\": non_null_properties[\"account_id\"]})\n",
    "                session.run(create_transaction_relationship_query, non_null_properties)\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating transaction relationship: {e}\")\n",
    "\n",
    "    \n",
    "    def load_data(self, external_parties_train, account_booking_train):\n",
    "        \"\"\"Load all data into Neo4j.\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            # Load nodes and relationships\n",
    "            self.load_external_parties(session, external_parties_train)\n",
    "            self.load_transactions_as_relationships(session, account_booking_train)\n",
    "\n",
    "# Initialize the Neo4j loader\n",
    "loader = Neo4jLoader(NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "\n",
    "try:\n",
    "    print(\"Creating constraints in Neo4j...\")\n",
    "    loader.create_constraints()\n",
    "\n",
    "    print(\"Loading data into Neo4j...\")\n",
    "    loader.load_data(external_parties_train, account_booking_train)\n",
    "    print(\"Data loaded successfully!\")\n",
    "finally:\n",
    "    loader.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSHEntityResolution:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    # Fetch data from Neo4j\n",
    "    def fetch_nodes(self):\n",
    "        query = \"\"\"\n",
    "        MATCH (n:External_Party)\n",
    "        RETURN id(n) AS node_id, n.parsed_name AS name, n.parsed_address_street_name AS street, n.parsed_address_city AS city\n",
    "        \"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(query)\n",
    "            return [(record[\"node_id\"], record[\"name\"], record[\"street\"], record[\"city\"]) for record in result]\n",
    "\n",
    "    # Generate MinHash for a given text\n",
    "    def generate_minhash(self, text, num_perm=128):\n",
    "        if not text:\n",
    "            return None\n",
    "        mh = MinHash(num_perm=num_perm)\n",
    "        for token in text.split():\n",
    "            mh.update(token.encode(\"utf8\"))\n",
    "        return mh\n",
    "\n",
    "    # Perform LSH on nodes\n",
    "    def perform_lsh(self, nodes, threshold=0.8, num_perm=128):\n",
    "        lsh = MinHashLSH(threshold=threshold, num_perm=num_perm)\n",
    "        node_hashes = {}\n",
    "\n",
    "        # Insert nodes into LSH\n",
    "        for node_id, name, street, city in nodes:\n",
    "            combined_text = \" \".join(filter(None, [name, street, city]))\n",
    "            mh = self.generate_minhash(combined_text, num_perm)\n",
    "            if mh:\n",
    "                lsh.insert(str(node_id), mh)\n",
    "                node_hashes[str(node_id)] = mh\n",
    "\n",
    "        # Find similar pairs\n",
    "        matches = []\n",
    "        for node_id, mh in node_hashes.items():\n",
    "            similar = lsh.query(mh)\n",
    "            for sim in similar:\n",
    "                if node_id < sim:  # Avoid duplicate matches (e.g., (A, B) and (B, A))\n",
    "                    matches.append((int(node_id), int(sim)))\n",
    "\n",
    "        return matches\n",
    "\n",
    "    # Save matches to Neo4j\n",
    "    def save_matches_to_neo4j(self, matches):\n",
    "        query = \"\"\"\n",
    "        UNWIND $pairs AS pair\n",
    "        MATCH (n1), (n2)\n",
    "        WHERE id(n1) = pair[0] AND id(n2) = pair[1]\n",
    "        MERGE (n1)-[:POSSIBLE_DUPLICATE]->(n2)\n",
    "        \"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            session.run(query, pairs=matches)\n",
    "\n",
    "    # Merge duplicate nodes in Neo4j\n",
    "    def merge_duplicate_nodes(self):\n",
    "        query = \"\"\"\n",
    "        // Match nodes connected by POSSIBLE_DUPLICATE relationships\n",
    "        MATCH (n)-[r:POSSIBLE_DUPLICATE]-(m)\n",
    "        WITH n, m\n",
    "        WHERE id(n) < id(m)  // To avoid processing the same pair twice\n",
    "\n",
    "        // Step 1: Merge properties from both nodes\n",
    "        SET n += m\n",
    "\n",
    "        // Step 2: Redirect incoming relationships to n\n",
    "        WITH n, m\n",
    "        MATCH (m)<-[rel]-(other)\n",
    "        MERGE (n)<-[newRel:TYPE(rel)]-(other)\n",
    "        ON CREATE SET newRel += properties(rel)\n",
    "\n",
    "        // Step 3: Redirect outgoing relationships to n\n",
    "        WITH n, m\n",
    "        MATCH (m)-[rel]->(other)\n",
    "        MERGE (n)-[newRel:TYPE(rel)]->(other)\n",
    "        ON CREATE SET newRel += properties(rel)\n",
    "\n",
    "        // Step 4: Delete duplicate node and POSSIBLE_DUPLICATE relationship\n",
    "        WITH m\n",
    "        DETACH DELETE m\n",
    "\n",
    "        \"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(query)\n",
    "            return result.single()[\"merged_nodes\"]\n",
    "\n",
    "    # Full workflow\n",
    "    def run_lsh_entity_resolution(self, threshold=0.8):\n",
    "        print(\"Fetching nodes from Neo4j...\")\n",
    "        nodes = self.fetch_nodes()\n",
    "        print(f\"Fetched {len(nodes)} nodes.\")\n",
    "\n",
    "        print(f\"Performing LSH with threshold {threshold}...\")\n",
    "        matches = self.perform_lsh(nodes, threshold=threshold)\n",
    "        print(f\"Found {len(matches)} matches.\")\n",
    "\n",
    "        print(\"Saving matches to Neo4j...\")\n",
    "        self.save_matches_to_neo4j(matches)\n",
    "\n",
    "        #print(\"Merging duplicate nodes in Neo4j...\")\n",
    "        #merged_nodes = self.merge_duplicate_nodes()\n",
    "        #print(f\"Total nodes merged: {merged_nodes}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    lsh_er = LSHEntityResolution(NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "    \n",
    "    try:\n",
    "        lsh_er.run_lsh_entity_resolution(threshold=0.8)\n",
    "    finally:\n",
    "        lsh_er.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Neo4jReset:\n",
    "\n",
    "    def __init__(self, uri, username, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "    \n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "    \n",
    "    def reset_database(self):\n",
    "        with self.driver.session() as session:\n",
    "            # Delete all nodes and relationships\n",
    "            session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "            \n",
    "            # Drop all constraints\n",
    "            constraints = session.run(\"SHOW CONSTRAINTS\")\n",
    "            for record in constraints:\n",
    "                constraint_name = record[\"name\"]\n",
    "                session.run(f\"DROP CONSTRAINT {constraint_name}\")\n",
    "\n",
    "            # Drop all indexes\n",
    "            indexes = session.run(\"SHOW INDEXES\")\n",
    "            for record in indexes:\n",
    "                index_name = record[\"name\"]\n",
    "                session.run(f\"DROP INDEX {index_name}\")\n",
    "\n",
    "# Initialize the Neo4jReset class\n",
    "resetter = Neo4jReset(NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "\n",
    "try:\n",
    "    print(\"Resetting Neo4j database...\")\n",
    "    resetter.reset_database()\n",
    "    print(\"Database reset successfully!\")\n",
    "finally:\n",
    "    resetter.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
