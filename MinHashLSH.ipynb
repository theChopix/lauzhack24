{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import uuid  # For generating unique IDs\n",
    "import math \n",
    "\n",
    "\n",
    "# Load CSV files\n",
    "account_booking_train = pd.read_csv('data/account_booking_train.csv')\n",
    "external_parties_train = pd.read_csv('data/external_parties_train.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct matches: 4516\n",
      "Number of wrong matches: 36\n"
     ]
    }
   ],
   "source": [
    "from datasketch import MinHash, MinHashLSH\n",
    "import pandas as pd\n",
    "\n",
    "class LSHEntityResolution:\n",
    "    def __init__(self, dataframe):\n",
    "        \"\"\"\n",
    "        Initialize with the DataFrame.\n",
    "        :param dataframe: Pandas DataFrame containing entity data.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    # Generate MinHash for a given text\n",
    "    def generate_minhash(self, text, num_perm=128):\n",
    "        \"\"\"\n",
    "        Create MinHash for a given text.\n",
    "        :param text: Input string.\n",
    "        :param num_perm: Number of permutations for MinHash.\n",
    "        :return: MinHash object.\n",
    "        \"\"\"\n",
    "        if not text or pd.isna(text):\n",
    "            return None\n",
    "        mh = MinHash(num_perm=num_perm)\n",
    "        for token in text.split():\n",
    "            mh.update(token.encode(\"utf8\"))\n",
    "        return mh\n",
    "\n",
    "    # Perform LSH on nodes\n",
    "    def perform_lsh(self, threshold=0.8, num_perm=128):\n",
    "        \"\"\"\n",
    "        Perform LSH to find similar entities.\n",
    "        :param threshold: Similarity threshold for LSH.\n",
    "        :param num_perm: Number of permutations for MinHash.\n",
    "        :return: List of matched entity pairs.\n",
    "        \"\"\"\n",
    "        lsh = MinHashLSH(threshold=threshold, num_perm=num_perm)\n",
    "        node_hashes = {}\n",
    "\n",
    "        # Insert nodes into LSH\n",
    "        for index, row in self.dataframe.iterrows():\n",
    "            combined_text = \" \".join(\n",
    "                filter(None, [\n",
    "                    str(row['parsed_name']), \n",
    "                    str(row['parsed_address_street_name']), \n",
    "                    str(row['parsed_address_city'])                    \n",
    "                ])\n",
    "            )\n",
    "            mh = self.generate_minhash(combined_text, num_perm)\n",
    "            if mh:\n",
    "                lsh.insert(str(index), mh)\n",
    "                node_hashes[str(index)] = mh\n",
    "\n",
    "        # Find similar pairs\n",
    "        matches = []\n",
    "        for node_id, mh in node_hashes.items():\n",
    "            similar = lsh.query(mh)\n",
    "            for sim in similar:\n",
    "                if int(node_id) < int(sim):  # Avoid duplicate matches (e.g., (A, B) and (B, A))\n",
    "                    matches.append((int(node_id), int(sim)))\n",
    "\n",
    "        return matches\n",
    "\n",
    "    def evaluate_matches(self, matches):\n",
    "        \"\"\"\n",
    "        Evaluate matches based on the 'external_id' column and print detailed results.\n",
    "        :param matches: List of matched entity pairs.\n",
    "        :return: Number of correct matches and a list of wrong matches.\n",
    "        \"\"\"\n",
    "        correct_matches = 0\n",
    "        wrong_matches = []\n",
    "\n",
    "        for match in matches:\n",
    "            id1, id2 = match\n",
    "            external_id1 = self.dataframe.loc[id1, 'external_id']\n",
    "            external_id2 = self.dataframe.loc[id2, 'external_id']\n",
    "            if external_id1 == external_id2:\n",
    "                correct_matches += 1\n",
    "            else:\n",
    "                wrong_matches.append((id1, id2, external_id1, external_id2))\n",
    "\n",
    "        return correct_matches, wrong_matches\n",
    "\n",
    "lsh_er = LSHEntityResolution(external_parties_train)\n",
    "matches = lsh_er.perform_lsh(threshold=0.6, num_perm=264)\n",
    "\n",
    "correct_match_count, wrong_matches = lsh_er.evaluate_matches(matches)\n",
    "\n",
    "# Print Results\n",
    "print(f\"Number of correct matches: {correct_match_count}\")\n",
    "print(f\"Number of wrong matches: {len(wrong_matches)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.992091388400703\n",
      "Recall: 0.32340303637926093\n",
      "F1 Score: 0.48779434003024413\n"
     ]
    }
   ],
   "source": [
    "def calculate_total_true_matches(df):\n",
    "    \"\"\"\n",
    "    Calculate the total number of true matches based on external_id.\n",
    "    \"\"\"\n",
    "    total_true_matches = 0\n",
    "    external_id_groups = df.groupby('external_id').size()\n",
    "    for count in external_id_groups:\n",
    "        if count > 1:\n",
    "            total_true_matches += count * (count - 1) // 2  # nC2 = n * (n - 1) / 2\n",
    "    return total_true_matches\n",
    "\n",
    "# Calculate the total true matches and F1 score components\n",
    "total_true_matches = calculate_total_true_matches(external_parties_train)\n",
    "false_negatives = total_true_matches - correct_match_count\n",
    "false_positives = len(wrong_matches)\n",
    "\n",
    "# Precision, Recall, and F1 Score\n",
    "precision = correct_match_count / (correct_match_count + false_positives) if (correct_match_count + false_positives) > 0 else 0\n",
    "recall = correct_match_count / (correct_match_count + false_negatives) if (correct_match_count + false_negatives) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# Print results\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
